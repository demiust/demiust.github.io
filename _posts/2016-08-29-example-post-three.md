---
title: Density-based novelty detection
categories: 
- General
excerpt: |
  Density-based novelty detection (Gaussian Density Estimation, Mixture of Gaussian, Kernel Density Estimation, LOF)
feature_text: |
  ## Density-based novelty detection
  이 글은 고려대학교 강필성 교수님의 Business Analytics 강의를 참조하였습니다.
feature_image: "https://picsum.photos/2560/600?image=733"
image: "https://picsum.photos/2560/600?image=733"
use_math: true
---

<h2> Novelty Detection이란? </h2> 

Novelty detection은 일반적인 데이터의 경향과는 다른 특이한 혹은 이상한 데이터(novel data, outliers)를 찾아내는 기술입니다. 예를 들어 갑자기 어떤 신용카드가 여태까지 쓰이지 않던 장소에서 쓰이지 않던 방식으로 쓰였다면 이것은 '이상한 데이터'라고 할 수 있습니다. Novelty detection은 이런 식의 이상성을 발견하고자 하는 알고리즘입니다.

<em> “Observations that deviate so much from other observations as to arouse suspicions that they were __generated by a different mechanism__ (Hawkins, 1980)”
“Instances that their __true probability density is very low__ (Harmelinget al., 2006)” </em>

위에서 정의된 것처럼 novel data(outliers)는 일반적인 데이터와 차이가 많이 나는 관측 데이터라고 볼 수 있습니다. 여기서 재밌는 점은 novel data는 __noise data와 다르다__ 는 점입니다. Noise는 데이터 전처리 과정에서 제거해줘야 할 데이터이기 때문에 novelty detection 이전에 제거하게 됩니다. 하지만 novel data는 일반적인 데이터를 만들어낸 메커니즘을 위반하는 특이한 케이스의 관측치들이기 때문에 novelty detection에서 찾아내고자 하는 관측치입니다.

<h2> 종류 </h2>
Novel data에는 크게 세 종류가 있습니다. 
* Global Outlier
image1

우리가 보는 일반적인 “outlier”라고 할 수 있습니다. 단순히 일반적인 관측치와 동떨어진 관측치들입니다.

* Contextual outlier(local outlier)
image2

특정 상황 혹은 맥락 정보를 고려해 “outlier”가 되는 경우입니다. 예를 들면, 알래스카의 영상 30도는 outlier라고 볼 수 있지만, 사하라 사막의 영상 30도는 outlier가 아닐 수 있습니다.

* Collective outlier

개별적인 관측치들이 outlier가 아니더라도, 데이터의 부분집합이 집단적으로 전체 데이터로부터 동떨어진 움직임이 있다면 이것을 collective outlier라고 합니다. 대표적으로 Dos attack이 있습니다.

<h3> Classification과의 차이 </h3>
Novelty Detection은 Classification과 차이가 있습니다. 

image3 
왼쪽의 그림에서처럼 Classification은 X와 O를 각각 X의 경우에는 “빨간색”의 범주로, O의 경우에는 “파란색”의 범주로 학습시킵니다. 즉, 각각의 범주를 학습시킵니다.
반면 오른쪽의 그림에서처럼 Novelty detection은 파란색만 데이터로 활용해 훈련해서, 결과적으로 파란색(정상) 범주에 포함되는지 포함되지 않는지만을 알아내는 것이 목적입니다.

Class Imbalance가 크고, minority class example의 개수가 충분하지 않을 때 우리는 novelty detection 알고리즘을 사용하고, 만약 class간의 imbalance가 크더라도 minority class example 데이터의 절대량이 크다면 비율을 맞춰서 classification 방식으로 훈련하는 것이 적합합니다. 즉, novelty detection은 classification 방식이 불가능할 때 대안 방법으로 사용할 수 있습니다.

<h3> Performance measure </h3>
Novelty detection 알고리즘의 평가는 다음과 같이 합니다.

image4
우선 normal data를 novel data로 분류한 경우와, novel data를 normal data로 분류한 경우가 적을 수록 이상한 데이터를 잘 가려내었다고 판단할 수 있습니다.

image5
normal data를 novel data로 분류한 경우의 에러는 False Rejection Rate(FRR)로 표현할 수 있고, novel data를 normal data로 분류한 경우의 에러는 False Acceptance Rate (FAR)로 표현할 수 있습니다.

image6
FRR과 FAR을 두 축으로 해서 FRR이 FAR과 같아질 때를 Equal error rate(EER)이라고 하고, FRR-FAR curve의 밑부분의 면적을 Integrated Error(IE)라고 합니다. Novelty detection 알고리즘은 EER과 IE가 낮을수록 좋다고 평가할 수 있습니다.


$ \frac { 3 }{ 4 } $

$$
K(a,b) = \int \mathcal{D}x(t) \exp(2\pi i S[x]/\hbar)
$$
